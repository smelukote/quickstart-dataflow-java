{
  "name": "Word Count",
  "description": "Batch pipeline. Reads text from Cloud Storage, tokenizes text lines into individual words, and performs frequency count on each of the words.",
  "parameters": [
    {
      "name": "inputFile",
      "label": "Input file(s) in Cloud Storage",
      "helpText": "The input file pattern Dataflow reads from. Use the example file (gs://dataflow-samples/shakespeare/kinglear.txt) or enter the path to your own using the same format: gs://your-bucket/your-file.txt",
      "regexes": [
        "^gs:\\/\\/[^\\n\\r]+$"
      ],
      "paramType": "GCS_READ_FILE"
    },
    {
      "name": "output",
      "label": "Output Cloud Storage file prefix",
      "helpText": "Path and filename prefix for writing output files. Ex: gs://your-bucket/counts",
      "regexes": [
        "^gs:\\/\\/[^\\n\\r]+$"
      ],
      "paramType": "GCS_WRITE_FOLDER"
    }
  ]
}